{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install streamlit langchain langchain-community langchain-google-genai faiss-cpu beautifulsoup4 lxml pyngrok google-ai-generativelanguage==0.6.15 --quiet"
      ],
      "metadata": {
        "id": "RK-qlr4d_NIt"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "\n",
        "# 1. REQUIRED IMPORTS\n",
        "\n",
        "import os\n",
        "import streamlit as st\n",
        "\n",
        "# LangChain and Google specific imports\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "\n",
        "\n",
        "# 2. PAGE CONFIGURATION AND STYLING\n",
        "\n",
        "# --- Page Configuration ---\n",
        "\n",
        "st.set_page_config(\n",
        "    page_title=\"Medical Literature Analysis\",\n",
        "    page_icon=\"ðŸ©º\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\"\n",
        ")\n",
        "\n",
        "# --- Custom CSS ---\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "    /* Main app background */\n",
        "    .main {\n",
        "        background-color: #f0f2f6; /* Light grey background */\n",
        "    }\n",
        "    /* Sidebar styling */\n",
        "    .st-emotion-cache-16txtl3 {\n",
        "        background-color: #ffffff;\n",
        "    }\n",
        "    /* Button styling */\n",
        "    .stButton>button {\n",
        "        border-radius: 8px;\n",
        "        border: 1px solid #0068c9;\n",
        "        background-color: #0068c9;\n",
        "        color: white;\n",
        "    }\n",
        "    .stButton>button:hover {\n",
        "        background-color: #00509e;\n",
        "        color: white;\n",
        "        border: 1px solid #00509e;\n",
        "    }\n",
        "    /* Expander styling */\n",
        "    .st-expander {\n",
        "        border: 1px solid #e0e0e0;\n",
        "        border-radius: 8px;\n",
        "    }\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "\n",
        "# 3. INITIALIZING API KEY AND MODEL\n",
        "\n",
        "\n",
        "# --- Handling API Key ---\n",
        "if 'GOOGLE_API_KEY' not in os.environ:\n",
        "    st.error(\"GOOGLE_API_KEY environment variable not found. The app cannot start.\")\n",
        "    st.stop()\n",
        "\n",
        "# --- Initialize Models ---\n",
        "try:\n",
        "    llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.3, convert_system_message_to_human=True, max_output_tokens=2048)\n",
        "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "except Exception as e:\n",
        "    st.error(f\"Error initializing Google AI models: {e}\")\n",
        "    st.stop()\n",
        "\n",
        "\n",
        "# 4. STREAMLIT UI AND APPLICATION LOGIC\n",
        "\n",
        "\n",
        "# --- Sidebar ---\n",
        "with st.sidebar:\n",
        "    st.title(\"ðŸ©º Analysis Engine\")\n",
        "    st.markdown(\"Enter the URLs of the medical articles you wish to analyze below.\")\n",
        "\n",
        "    with st.form(\"input_form\"):\n",
        "        url1 = st.text_input(\"URL 1\", key=\"url1\")\n",
        "        url2 = st.text_input(\"URL 2\", key=\"url2\")\n",
        "        url3 = st.text_input(\"URL 3\", key=\"url3\")\n",
        "        process_button = st.form_submit_button(label=\"Analyze Articles\")\n",
        "\n",
        "# --- Main Page Title ---\n",
        "st.title(\"Medical Literature Intelligence\")\n",
        "st.subheader(\"Your AI-Powered Research Assistant\")\n",
        "st.divider()\n",
        "\n",
        "# --- Initializing Session State  ---\n",
        "if \"processed\" not in st.session_state:\n",
        "    st.session_state.processed = False\n",
        "    st.session_state.vector_store = None\n",
        "    st.session_state.docs = None\n",
        "\n",
        "# --- Main Processing Logic ---\n",
        "if process_button:\n",
        "    urls = [url for url in [url1, url2, url3] if url.strip()]\n",
        "    if not urls:\n",
        "        st.sidebar.warning(\"Please enter at least one valid URL.\")\n",
        "    else:\n",
        "        with st.spinner(\"Analyzing content... This may take a moment.\"):\n",
        "            try:\n",
        "                loader = WebBaseLoader(web_paths=urls)\n",
        "                docs = loader.load()\n",
        "                text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)\n",
        "                texts = text_splitter.split_documents(docs)\n",
        "                if not texts:\n",
        "                    st.error(\"Could not extract any text from the provided URLs. Please check the links.\")\n",
        "                else:\n",
        "                    vector_store = FAISS.from_documents(texts, embedding=embeddings)\n",
        "                    st.session_state.vector_store = vector_store\n",
        "                    st.session_state.docs = docs\n",
        "                    st.session_state.processed = True\n",
        "                    st.sidebar.success(\"Analysis complete!\")\n",
        "            except Exception as e:\n",
        "                st.sidebar.error(f\"An error occurred: {e}\")\n",
        "                st.session_state.processed = False\n",
        "\n",
        "# --- Displaying Results ---\n",
        "if st.session_state.processed:\n",
        "    st.header(\"Analysis Results\", anchor=False)\n",
        "\n",
        "    # --- Summary Section ---\n",
        "    with st.expander(\"**Executive Summary of Articles**\", expanded=True):\n",
        "        with st.spinner(\"Generating summary...\"):\n",
        "            summarize_chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
        "            summary = summarize_chain.run(st.session_state.docs)\n",
        "            st.write(summary)\n",
        "\n",
        "    # --- Q&A Section ---\n",
        "    with st.expander(\"**Question & Answer based on Articles**\", expanded=True):\n",
        "        query = st.text_input(\"Ask a specific question about the content:\", placeholder=\"e.g., What were the primary endpoints of the study?\")\n",
        "        if query:\n",
        "            with st.spinner(\"Searching for the answer...\"):\n",
        "                qa_chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
        "                    llm=llm, chain_type=\"stuff\", retriever=st.session_state.vector_store.as_retriever()\n",
        "                )\n",
        "                result = qa_chain({\"question\": query}, return_only_outputs=True)\n",
        "\n",
        "                st.subheader(\"Answer\", anchor=False)\n",
        "                st.success(result['answer'])\n",
        "\n",
        "                st.subheader(\"Sources\", anchor=False)\n",
        "                st.info(result['sources'])\n",
        "else:\n",
        "    st.info(\"Enter article URLs in the sidebar and click 'Analyze Articles' to begin.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqydpX6h_Uw1",
        "outputId": "5883472e-cb47-4968-f71b-a8c742b3e916"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3:\n",
        "from pyngrok import ngrok\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Get secrets from Colab\n",
        "try:\n",
        "    NGROK_AUTHTOKEN = userdata.get('NGROK_AUTHTOKEN')\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "except Exception as e:\n",
        "    print(f\"ERROR: Failed to get key. Please double check them. Error: {e}\")\n",
        "else:\n",
        "    # Setting ngrok authtoken\n",
        "    ngrok.set_auth_token(NGROK_AUTHTOKEN)\n",
        "\n",
        "    # Terminate any existing ngrok tunnels\n",
        "    ngrok.kill()\n",
        "\n",
        "    # Create the public URL\n",
        "    public_url = ngrok.connect(8501)\n",
        "    print(\"App is live!\")\n",
        "    print(f\"ðŸ”— Public URL: {public_url}\")\n",
        "\n",
        "    # Set the GOOGLE_API_KEY as an environment variable for the streamlit command\n",
        "    !GOOGLE_API_KEY={GOOGLE_API_KEY} streamlit run app.py --server.port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krLmz7K1_Y1S",
        "outputId": "f6a7418b-87ad-44b3-956c-21cc7937a755"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Your app is live!\n",
            "ðŸ”— Public URL: NgrokTunnel: \"https://0dc1-34-86-192-55.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.86.192.55:8501\u001b[0m\n",
            "\u001b[0m\n",
            "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
            "/content/app.py:136: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  summary = summarize_chain.run(st.session_state.docs)\n",
            "/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}